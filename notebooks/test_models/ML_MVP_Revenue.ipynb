{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML: MVP-Revenue.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBwht1XfyWC"
      },
      "source": [
        "##Modelo de predicción del Revenue de punta a punta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po1WlzbZXQXK"
      },
      "source": [
        "Abrimos el csv e importamos algunas librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nmi9B99j6vL",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "454b2b29-fe77-42fc-e0cf-bb39bfce6bda"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3fef7e5d-74e6-4017-9f40-b79c3111b52f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3fef7e5d-74e6-4017-9f40-b79c3111b52f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving movies_metadata.csv to movies_metadata (3).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RnsnVP5XDxf"
      },
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np\r\n",
        "import io"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oblb6mvof0Ju",
        "outputId": "e52d82fb-f02f-41c8-acfa-44df6ce90c89"
      },
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded['movies_metadata.csv']))"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaa2THMrXUAq"
      },
      "source": [
        "###Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLjd4_gFXYAe"
      },
      "source": [
        "####Revenue:\r\n",
        "1. Quitamos valores menores o iguales a 0.\r\n",
        "2. Filtramos el 5% de los valores mas bajos para evitar errores de tipeo.\r\n",
        "3. Normalizamos aplicando el logaritmo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH-Z6aacmc1b"
      },
      "source": [
        "df = df[df.revenue > 0]\r\n",
        "df = df[df.revenue > df.revenue.quantile(.05)]\r\n",
        "\r\n",
        "import math\r\n",
        "def revenue_log(x):\r\n",
        "  return math.log(x)\r\n",
        "\r\n",
        "df['revenue'] = df.revenue.apply(lambda x: revenue_log(x))"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oclWQ06BXlhR"
      },
      "source": [
        "####Runtime:\r\n",
        "1. Sacamos valores nulos\r\n",
        "2. Sacamos valores que esten a mas o menos de 2 desviaciones estandar de la media."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVg1KTJpIFM4"
      },
      "source": [
        "df.fillna(0, inplace= True)\r\n",
        "df = df[df.runtime != 0]\r\n",
        "upper_lim = np.mean(df.runtime) + np.std(df.runtime)*2\r\n",
        "lower_lim = np.mean(df.runtime) - np.std(df.runtime)*2\r\n",
        "\r\n",
        "df = df[df.runtime > lower_lim]\r\n",
        "df = df[df.runtime < upper_lim]"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd0RmOheXx4-"
      },
      "source": [
        "####Release Date:\r\n",
        "1. Convertimos a tipo de dato datetime.\r\n",
        "2. Nos quedamos solo con el año.\r\n",
        "3. Filtramos todas aquellas peliculas anteriores al 1985"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3ceOdo56c6b"
      },
      "source": [
        "df['release_date'] = pd.to_datetime(df['release_date'])\r\n",
        "df['year'] = pd.DatetimeIndex(df['release_date']).year\r\n",
        "df = df[df.year > 1985]\r\n",
        "df.drop(columns = ['release_date'], inplace = True)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm38Y-g0YBQP"
      },
      "source": [
        "#### Géneros, Países y Colecciones:\r\n",
        "1. Convertimos los diccionarios a listas, quedandonos solo con el valor que nos interesa (name).\r\n",
        "2. En el caso de colecciones dado que hay >700 collections con frecuencias bajas la convertimos en un tipo de dato binario. 1 si es parte de una coleccion, 0 caso contrario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GAmPUT0k2Ca"
      },
      "source": [
        "#Desarmo diccionarios y convierto en listas\r\n",
        "\r\n",
        "#Géneros\r\n",
        "df['genres'] = df.genres.apply(lambda x: [i['name']  for i in eval(x)])\r\n",
        "\r\n",
        "#Países\r\n",
        "df['production_countries'] = df.production_countries.apply(lambda x: [i['name']  for i in eval(x)])\r\n",
        "\r\n",
        "#Colecciones\r\n",
        "df['belongs_to_collection'].fillna(0, inplace = True)\r\n",
        "import ast\r\n",
        "def collection_from_dict(x):\r\n",
        "  if x != 0:\r\n",
        "   #convert string to dictionary\r\n",
        "    res = ast.literal_eval(x) \r\n",
        "    #return just the name of the collection\r\n",
        "    return 1\r\n",
        "  return 0\r\n",
        "df['belongs_to_collection'] = df.belongs_to_collection.apply(lambda x: collection_from_dict(x))\r\n"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPpFprJNYWTo"
      },
      "source": [
        "###Feature Selection:\r\n",
        "1. Elegimos que variables dropear del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptcykZy_f1rE"
      },
      "source": [
        "df=df.drop(columns = ['adult','budget','homepage','id','original_title',\r\n",
        "                     'overview','popularity','poster_path','production_companies',\r\n",
        "                     'spoken_languages','status', 'tagline', 'title', 'video',\r\n",
        "                     'vote_average','vote_count'], axis=1)\r\n"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHtLKpUuYeLZ"
      },
      "source": [
        "###Train and test split:\r\n",
        "1. Cortamos por año (2014) dado que queremos que el modelo aprenda a predecir películas del futuro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTyyzAojhOcH",
        "outputId": "1fdd0a23-7492-47d2-c860-7b89ae3f312f"
      },
      "source": [
        "train_df = df[df.year <= 2014]\r\n",
        "test_df = df[df.year > 2014]\r\n",
        "len(train_df), len(test_df), len(test_df) / len(train_df)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5096, 647, 0.12696232339089483)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gjveGTE62cI"
      },
      "source": [
        "y_train = (train_df.revenue).values\r\n",
        "y_test = (test_df.revenue).values"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j557gxzXYorq"
      },
      "source": [
        "###Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4NpY8a6Y0_O"
      },
      "source": [
        "Vamos a usar todo como listas de diccionarios para poder usar el ecosistema de sklearn de forma sencilla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ankmLhaurMWb"
      },
      "source": [
        "train_docs = train_df.to_dict(orient='records')\r\n",
        "test_docs = test_df.to_dict(orient='records')"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVY1f6qE2UPa",
        "outputId": "341af6eb-843b-4cde-8b6e-eb6eb989c5ee"
      },
      "source": [
        "train_docs[0], test_docs[0]"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'belongs_to_collection': 1,\n",
              "  'genres': ['Animation', 'Comedy', 'Family'],\n",
              "  'imdb_id': 'tt0114709',\n",
              "  'original_language': 'en',\n",
              "  'production_countries': ['United States of America'],\n",
              "  'revenue': 19.7385732187406,\n",
              "  'runtime': 81.0,\n",
              "  'year': 1995},\n",
              " {'belongs_to_collection': 1,\n",
              "  'genres': ['Action', 'Adventure', 'Thriller'],\n",
              "  'imdb_id': 'tt2381249',\n",
              "  'original_language': 'en',\n",
              "  'production_countries': ['China', 'United States of America'],\n",
              "  'revenue': 20.341024173461395,\n",
              "  'runtime': 131.0,\n",
              "  'year': 2015})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFwJCwVrY6BE"
      },
      "source": [
        "####Feature Géneros:\r\n",
        "1. Hacemos variables dummies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmW8VIMbkjbr"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
        "\r\n",
        "class GenreDummies(BaseEstimator, TransformerMixin):\r\n",
        "    def fit(self, X, y): return self\r\n",
        "\r\n",
        "    def transform(self, X):\r\n",
        "        res = []\r\n",
        "        for e in X:\r\n",
        "            res.append({g: 1 for g in e['genres']})\r\n",
        "        return res"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWLgmbTw9_qK"
      },
      "source": [
        "####Features Belongs to Collection y Language:\r\n",
        "1. Hacemos una clase que las devuelva como estan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUeJe5qx4f18"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
        "\r\n",
        "class BelongsToCollection(BaseEstimator, TransformerMixin):\r\n",
        "    def fit(self, X, y): return self\r\n",
        "\r\n",
        "    def transform(self, X):\r\n",
        "        res = []\r\n",
        "        for e in X:\r\n",
        "            res.append({'belongs to collection': e['belongs_to_collection']})\r\n",
        "        return res"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytT9VDXv9kA0"
      },
      "source": [
        "class Language(BaseEstimator, TransformerMixin):\r\n",
        "    def fit(self, X, y): return self\r\n",
        "\r\n",
        "    def transform(self, X):\r\n",
        "        res = []\r\n",
        "        for e in X:\r\n",
        "            res.append({'language': e['original_language']})\r\n",
        "        return res"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBM3Xubw-ITg"
      },
      "source": [
        "####Feature Runtime:\r\n",
        "1. Hacemos una clase que la devuelva tal cual está pero luego la normalizamos en el pipeline con StandardScaler()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmdulKYA9NX-"
      },
      "source": [
        "class Runtime(BaseEstimator, TransformerMixin):\r\n",
        "    def fit(self, X, y): return self\r\n",
        "\r\n",
        "    def transform(self, X):\r\n",
        "        res = []\r\n",
        "        for e in X:\r\n",
        "            res.append({'runtime': e['runtime']})\r\n",
        "        return res"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP8x4igG7xh6"
      },
      "source": [
        "####Feature años:\r\n",
        "1. Armamos una variable que indique hace cuantos años se filmo la pelicula."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXpwscqE7yXp"
      },
      "source": [
        "from datetime import datetime\r\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
        "\r\n",
        "class YearsAgo(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self):\r\n",
        "        self.now = datetime.now().year\r\n",
        "        \r\n",
        "    def fit(self, X, y): return self\r\n",
        "\r\n",
        "    def transform(self, X):\r\n",
        "        res = []\r\n",
        "        for e in X:\r\n",
        "            res.append({'years_ago': self.now - int(e['year'])})\r\n",
        "        return res"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63VWunkeZ8zJ"
      },
      "source": [
        "####Feature países:\r\n",
        "1. Armamos variables dummies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjS6ncWN94xw"
      },
      "source": [
        "class CountryDummies(BaseEstimator, TransformerMixin):\r\n",
        "    def fit(self, X, y): return self\r\n",
        "\r\n",
        "    def transform(self, X):\r\n",
        "        res = []\r\n",
        "        for e in X:\r\n",
        "            res.append({g: 1 for g in e['production_countries']})\r\n",
        "        return res"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol-BesSKZR5e"
      },
      "source": [
        "###Performance metrics:\r\n",
        "1. Medimos el mean absolute percentage error (mape) y el r2 para el train y test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh2iwdwr41gW"
      },
      "source": [
        "def test_pipe(pipe):\r\n",
        "    return {\r\n",
        "        'train_mape' : round(np.mean(np.abs(percentage_error(np.asarray(y_train), np.asarray(pipe.predict(train_docs))))) * 100,2),\r\n",
        "        'test_mape' : round(np.mean(np.abs(percentage_error(np.asarray(y_test), np.asarray(pipe.predict(test_docs))))) * 100,2)\r\n",
        "    }\r\n",
        "\r\n",
        "def percentage_error(actual, predicted):\r\n",
        "    res = np.empty(actual.shape)\r\n",
        "    for j in range(actual.shape[0]):\r\n",
        "        if actual[j] != 0:\r\n",
        "            res[j] = (actual[j] - predicted[j]) / actual[j]\r\n",
        "        else:\r\n",
        "            res[j] = predicted[j] / np.mean(actual)\r\n",
        "    return res"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3mbw70oadtB"
      },
      "source": [
        "###Armamos el Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VLwclqWrfJR"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.feature_extraction import DictVectorizer\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVgDkTHR-qaa"
      },
      "source": [
        "#####Regresión Lineal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC146oKIFCRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f4d4b5d-a9e5-45db-ab82-974f4f9c2d6e"
      },
      "source": [
        "pipe = make_pipeline(\r\n",
        "    make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))      \r\n",
        "    ),\r\n",
        "    StandardScaler(),\r\n",
        "    LinearRegression()\r\n",
        ")\r\n",
        "\r\n",
        "pipe.fit(train_docs, y_train);\r\n",
        "lin_reg = test_pipe(pipe)\r\n",
        "lin_reg"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_mape': 10.66, 'train_mape': 8.99}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEjqGR6JJ0PY"
      },
      "source": [
        "#####Ridge Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J3rkBOpc_zC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60cd6bdc-8f55-4128-eaff-255c7bd16756"
      },
      "source": [
        "from sklearn.linear_model import Ridge\r\n",
        "alphas = [0.01, 0.1, 1, 10, 100, 500, 1000]\r\n",
        "for alpha in alphas:\r\n",
        "  pipe = make_pipeline(\r\n",
        "      make_union(\r\n",
        "          make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "          make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "          make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "          make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "          make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "          make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))         \r\n",
        "      ),\r\n",
        "      StandardScaler(),\r\n",
        "      Ridge(alpha=alpha)\r\n",
        "  )\r\n",
        "  pipe.fit(train_docs, y_train);\r\n",
        "  print('alpha:', alpha)\r\n",
        "  print(test_pipe(pipe))"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alpha: 0.01\n",
            "{'train_r2': 0.4, 'train_mape': 8.95, 'test_r2': 0.4, 'test_mape': 10.67}\n",
            "alpha: 0.1\n",
            "{'train_r2': 0.4, 'train_mape': 8.95, 'test_r2': 0.4, 'test_mape': 10.67}\n",
            "alpha: 1\n",
            "{'train_r2': 0.4, 'train_mape': 8.95, 'test_r2': 0.4, 'test_mape': 10.67}\n",
            "alpha: 10\n",
            "{'train_r2': 0.4, 'train_mape': 8.95, 'test_r2': 0.4, 'test_mape': 10.67}\n",
            "alpha: 100\n",
            "{'train_r2': 0.4, 'train_mape': 8.96, 'test_r2': 0.4, 'test_mape': 10.67}\n",
            "alpha: 500\n",
            "{'train_r2': 0.4, 'train_mape': 9.03, 'test_r2': 0.4, 'test_mape': 10.71}\n",
            "alpha: 1000\n",
            "{'train_r2': 0.39, 'train_mape': 9.13, 'test_r2': 0.4, 'test_mape': 10.82}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOQNiqQqYzaU"
      },
      "source": [
        "No hay mucho efecto de regularizarlo con Ridge en el conjunto de test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHI4uZEDaZMU"
      },
      "source": [
        "#####Red Neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb0ppbtKDe8B"
      },
      "source": [
        "from sklearn.neural_network import MLPRegressor"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faIcwvmMDaOh",
        "outputId": "8d18f3b1-b954-4e27-99cf-b53878611489"
      },
      "source": [
        "pipe = make_pipeline(\r\n",
        "    make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))      \r\n",
        "    ),\r\n",
        "    StandardScaler(),\r\n",
        "    MLPRegressor(random_state=21, solver = 'lbfgs')\r\n",
        ")\r\n",
        "\r\n",
        "pipe.fit(train_docs, y_train);\r\n",
        "test_pipe(pipe)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_mape': 13.76, 'test_r2': -0.23, 'train_mape': 5.58, 'train_r2': 0.71}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwJzrRhBe0I7"
      },
      "source": [
        "###### Tuneo de hiperparámetros:\r\n",
        "Con solver *lbfgs*:\r\n",
        "1. Busco óptimo nivel de alpha para regularizar.\r\n",
        "2. Busco óptima cantidad de iteraciones (max_iter)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA9b4u4ARlVy"
      },
      "source": [
        "Hiperparámetro alpha:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFaS9BRdKB8e"
      },
      "source": [
        "alphas = (168, 169, 170, 171, 172)\r\n",
        "for alpha in alphas:\r\n",
        "  pipe = make_pipeline(\r\n",
        "      make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))        \r\n",
        "    ),\r\n",
        "      StandardScaler(),\r\n",
        "      MLPRegressor(alpha=alpha, random_state=21, max_iter=200, \r\n",
        "                   early_stopping=True, solver = 'lbfgs')\r\n",
        "    )\r\n",
        "  pipe.fit(train_docs, y_train);\r\n",
        "  print('alpha:',alpha)\r\n",
        "  print(test_pipe(pipe))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmELMLqSe8fE"
      },
      "source": [
        "Hiperparámetro max_iter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfCVVSJYaMLJ"
      },
      "source": [
        "iters = (100, 200, 300, 400, 500)\r\n",
        "for iter in iters:\r\n",
        "  pipe = make_pipeline(\r\n",
        "      make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))        \r\n",
        "    ),\r\n",
        "      StandardScaler(),\r\n",
        "      MLPRegressor(alpha=170, random_state=21, max_iter=iter, \r\n",
        "                   early_stopping=True, solver = 'lbfgs')\r\n",
        "    )\r\n",
        "  pipe.fit(train_docs, y_train);\r\n",
        "  print('iters:' ,iter)\r\n",
        "  print(test_pipe(pipe))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BxhBSzWP9XH"
      },
      "source": [
        "Mejor resultado con alpha = 170 y max_iter = 300"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlv0r8HxPxBg",
        "outputId": "60675e24-1000-48c8-8f2f-90ad3aa04eca"
      },
      "source": [
        "pipe = make_pipeline(\r\n",
        "      make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))        \r\n",
        "    ),\r\n",
        "      StandardScaler(),\r\n",
        "      MLPRegressor(alpha=170, random_state=21, max_iter=300, \r\n",
        "                   early_stopping=True, solver = 'lbfgs')\r\n",
        "    )\r\n",
        "pipe.fit(train_docs, y_train);\r\n",
        "red_neu_lbfgs = test_pipe(pipe)\r\n",
        "print(red_neu_lbfgs)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train_mape': 7.92, 'test_mape': 10.27}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCFTy1IZRBDq"
      },
      "source": [
        "###### Tuneo de hiperparámetros:\r\n",
        "Con solver *sgd*:\r\n",
        "1. Busco óptimo nivel de alpha para regularizar.\r\n",
        "2. Busco óptimo nivel de learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iOQPJKmRDQN",
        "outputId": "d10efc52-17ee-42be-8878-3f150c570b9d"
      },
      "source": [
        "pipe = make_pipeline(\r\n",
        "    make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))      \r\n",
        "    ),\r\n",
        "    StandardScaler(),\r\n",
        "    MLPRegressor(random_state=21, solver = 'sgd')\r\n",
        ")\r\n",
        "\r\n",
        "pipe.fit(train_docs, y_train);\r\n",
        "test_pipe(pipe)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_mape': 10.61, 'test_r2': 0.37, 'train_mape': 7.33, 'train_r2': 0.56}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3dTG6dEhH4j"
      },
      "source": [
        "Hiperparámetro alpha:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnrqGzzlRQxE"
      },
      "source": [
        "alphas = (14, 15, 16, 17, 18, 19, 20, 21, 22, 25)\r\n",
        "for alpha in alphas:\r\n",
        "  pipe = make_pipeline(\r\n",
        "      make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))        \r\n",
        "    ),\r\n",
        "      StandardScaler(),\r\n",
        "      MLPRegressor(alpha=alpha, random_state=21,\r\n",
        "                   early_stopping=True, solver = 'sgd')\r\n",
        "    )\r\n",
        "  pipe.fit(train_docs, y_train);\r\n",
        "  print('alpha:',alpha)\r\n",
        "  print(test_pipe(pipe))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tul5uIXPg7R5"
      },
      "source": [
        "Hiperparámetro learning rate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvhrfwNJfPkB",
        "outputId": "99e96279-2e57-4d90-93e8-fe7325074ab4"
      },
      "source": [
        "lrates = (0.00001, 0.0001, 0.001)\r\n",
        "for lr in lrates:\r\n",
        "  pipe = make_pipeline(\r\n",
        "      make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))        \r\n",
        "    ),\r\n",
        "      StandardScaler(),\r\n",
        "      MLPRegressor(alpha=19, random_state=21,\r\n",
        "                   early_stopping=True, solver = 'sgd',\r\n",
        "                   learning_rate_init = lr,\r\n",
        "                   max_iter = 2000)\r\n",
        "    )\r\n",
        "  pipe.fit(train_docs, y_train);\r\n",
        "  print('Learning rate:' , lr)\r\n",
        "  print(test_pipe(pipe))"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Learning rate: 1e-05\n",
            "{'train_r2': 0.35, 'train_mape': 8.7, 'test_r2': 0.4, 'test_mape': 10.62}\n",
            "Learning rate: 0.0001\n",
            "{'train_r2': 0.44, 'train_mape': 8.58, 'test_r2': 0.41, 'test_mape': 10.51}\n",
            "Learning rate: 0.001\n",
            "{'train_r2': 0.44, 'train_mape': 8.57, 'test_r2': 0.41, 'test_mape': 10.49}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OqTe8JaUxlN",
        "outputId": "1c200688-442a-4600-9508-b7a523e06bd8"
      },
      "source": [
        "lrates = (0.0005, 0.0007, 0.001, 0.002, 0.003, 0.004, 0.005)\r\n",
        "for lr in lrates:\r\n",
        "  pipe = make_pipeline(\r\n",
        "      make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))        \r\n",
        "    ),\r\n",
        "      StandardScaler(),\r\n",
        "      MLPRegressor(alpha=19, random_state=21,\r\n",
        "                   early_stopping=True, solver = 'sgd',\r\n",
        "                   learning_rate_init = lr,\r\n",
        "                   max_iter = 2000)\r\n",
        "    )\r\n",
        "  pipe.fit(train_docs, y_train);\r\n",
        "  print('Learning rate:' , lr)\r\n",
        "  print(test_pipe(pipe))"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate: 0.0005\n",
            "{'train_r2': 0.44, 'train_mape': 8.57, 'test_r2': 0.41, 'test_mape': 10.51}\n",
            "Learning rate: 0.0007\n",
            "{'train_r2': 0.44, 'train_mape': 8.58, 'test_r2': 0.41, 'test_mape': 10.5}\n",
            "Learning rate: 0.001\n",
            "{'train_r2': 0.44, 'train_mape': 8.57, 'test_r2': 0.41, 'test_mape': 10.49}\n",
            "Learning rate: 0.002\n",
            "{'train_r2': 0.44, 'train_mape': 8.62, 'test_r2': 0.4, 'test_mape': 10.64}\n",
            "Learning rate: 0.003\n",
            "{'train_r2': 0.43, 'train_mape': 8.72, 'test_r2': 0.39, 'test_mape': 10.78}\n",
            "Learning rate: 0.004\n",
            "{'train_r2': 0.42, 'train_mape': 8.79, 'test_r2': 0.4, 'test_mape': 10.62}\n",
            "Learning rate: 0.005\n",
            "{'train_r2': 0.42, 'train_mape': 8.74, 'test_r2': 0.4, 'test_mape': 10.63}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwWTLmBPUqtD"
      },
      "source": [
        "Mejor resultado con alpha = 19 y learning rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYepMKdsUnnR",
        "outputId": "ca5d8b65-b70d-444a-8f9f-ca4b181dc306"
      },
      "source": [
        "pipe = make_pipeline(\r\n",
        "      make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))        \r\n",
        "    ),\r\n",
        "      StandardScaler(),\r\n",
        "      MLPRegressor(alpha=19, random_state=21, max_iter=500, \r\n",
        "                   early_stopping=True, solver = 'sgd', learning_rate_init=0.001)\r\n",
        "    )\r\n",
        "pipe.fit(train_docs, y_train);\r\n",
        "red_neu_sgd = test_pipe(pipe)\r\n",
        "print(red_neu_sgd)"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train_mape': 8.57, 'test_mape': 10.49}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_JZ4WJYhnfB"
      },
      "source": [
        "###### Tuneo de hiperparámetros:\r\n",
        "Con solver *Adam*:\r\n",
        "1. Busco óptimo nivel de alpha para regularizar.\r\n",
        "2. Busco óptimo nivel de learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzvhgbwfVzZi"
      },
      "source": [
        "Hiperparámetro alpha:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg4zMoVNgEwo"
      },
      "source": [
        "alphas = (16, 17, 18, 19, 20, 21, 22, 23, 24)\r\n",
        "for alpha in alphas:\r\n",
        "  pipe = make_pipeline(\r\n",
        "      make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))        \r\n",
        "    ),\r\n",
        "      StandardScaler(),\r\n",
        "      MLPRegressor(alpha=alpha, random_state=21,\r\n",
        "                   early_stopping=True, solver = 'adam')\r\n",
        "    )\r\n",
        "  pipe.fit(train_docs, y_train);\r\n",
        "  print('alpha:',alpha)\r\n",
        "  print(test_pipe(pipe))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCvU-Lx0W_Fv"
      },
      "source": [
        "Hiperparámetro learning rate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU1z-kruhgxJ",
        "outputId": "5add1d06-ebbc-4987-cf0b-130d1ff11e32"
      },
      "source": [
        "lrates = (0.0005, 0.0008, 0.001, 0.0015, 0.002, 0.003, 0.004)\r\n",
        "for lr in lrates:\r\n",
        "  pipe = make_pipeline(\r\n",
        "      make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))        \r\n",
        "    ),\r\n",
        "      StandardScaler(),\r\n",
        "      MLPRegressor(alpha=23, random_state=21,\r\n",
        "                   early_stopping=True, solver = 'adam',\r\n",
        "                   learning_rate_init = lr,\r\n",
        "                   max_iter = 500)\r\n",
        "    )\r\n",
        "  pipe.fit(train_docs, y_train);\r\n",
        "  print('Learning rate:' , lr)\r\n",
        "  print(test_pipe(pipe))"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate: 0.0005\n",
            "{'train_mape': 8.54, 'test_mape': 10.54}\n",
            "Learning rate: 0.0008\n",
            "{'train_mape': 8.57, 'test_mape': 10.56}\n",
            "Learning rate: 0.001\n",
            "{'train_mape': 8.62, 'test_mape': 10.44}\n",
            "Learning rate: 0.0015\n",
            "{'train_mape': 8.75, 'test_mape': 10.57}\n",
            "Learning rate: 0.002\n",
            "{'train_mape': 8.97, 'test_mape': 10.67}\n",
            "Learning rate: 0.003\n",
            "{'train_mape': 9.11, 'test_mape': 10.27}\n",
            "Learning rate: 0.004\n",
            "{'train_mape': 9.11, 'test_mape': 10.9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOyHb3gmYIUg"
      },
      "source": [
        "Mejor resultado con alpha = 23 y learning rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dg72r7MX9px",
        "outputId": "7b11176f-113d-4ceb-bc31-ec01b73c67e7"
      },
      "source": [
        "pipe = make_pipeline(\r\n",
        "      make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))        \r\n",
        "    ),\r\n",
        "      StandardScaler(),\r\n",
        "      MLPRegressor(alpha=23, random_state=21, \r\n",
        "                   early_stopping=True, solver = 'adam',\r\n",
        "                   learning_rate_init=0.001)\r\n",
        "    )\r\n",
        "pipe.fit(train_docs, y_train);\r\n",
        "red_neu_adam = test_pipe(pipe)\r\n",
        "print(red_neu_adam)"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train_mape': 8.62, 'test_mape': 10.44}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZIFo7odYslg"
      },
      "source": [
        "####Winner Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mpe8dHdYt90",
        "outputId": "7ed95ab0-5369-4182-842b-01ae0c73c476"
      },
      "source": [
        "lin_reg, red_neu_adam, red_neu_lbfgs, red_neu_sgd"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'test_mape': 10.66, 'train_mape': 8.99},\n",
              " {'test_mape': 10.44, 'train_mape': 8.62},\n",
              " {'test_mape': 10.27, 'train_mape': 7.92},\n",
              " {'test_mape': 10.49, 'train_mape': 8.57})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vu6bSZ0ZnfK",
        "outputId": "9c913da9-f2cb-40d3-d2c9-19a263a44c3b"
      },
      "source": [
        "lin_reg['test_mape']-lin_reg['train_mape']"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.67"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "uSPnTDNvZsQC",
        "outputId": "967badd3-c0d4-4fed-90e6-5463cbcbaa90"
      },
      "source": [
        "models = {\r\n",
        "    'models': ['linear regression', 'red neuronal lbfgs', 'red neuronal sgd', 'red neuronal adam'],\r\n",
        "    'test mape': [lin_reg['test_mape'], red_neu_lbfgs['test_mape'], red_neu_sgd['test_mape'], red_neu_adam['test_mape']],\r\n",
        "    'overfitting':[lin_reg['test_mape']-lin_reg['train_mape'], red_neu_lbfgs['test_mape']-red_neu_lbfgs['train_mape'],\r\n",
        "                   red_neu_sgd['test_mape']-red_neu_sgd['train_mape'], red_neu_adam['test_mape']-red_neu_adam['train_mape']]\r\n",
        "          }\r\n",
        "\r\n",
        "results = pd.DataFrame(models)\r\n",
        "results"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>models</th>\n",
              "      <th>test mape</th>\n",
              "      <th>overfitting</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>linear regression</td>\n",
              "      <td>10.66</td>\n",
              "      <td>1.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>red neuronal lbfgs</td>\n",
              "      <td>10.27</td>\n",
              "      <td>2.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>red neuronal sgd</td>\n",
              "      <td>10.49</td>\n",
              "      <td>1.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>red neuronal adam</td>\n",
              "      <td>10.44</td>\n",
              "      <td>1.82</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               models  test mape  overfitting\n",
              "0   linear regression      10.66         1.67\n",
              "1  red neuronal lbfgs      10.27         2.35\n",
              "2    red neuronal sgd      10.49         1.92\n",
              "3   red neuronal adam      10.44         1.82"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "0AJ6bHtyayzA",
        "outputId": "03d57a64-29d5-4a49-e748-6b6191e59a01"
      },
      "source": [
        "results.sort_values(by = 'test mape', ascending=True)"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>models</th>\n",
              "      <th>test mape</th>\n",
              "      <th>overfitting</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>red neuronal lbfgs</td>\n",
              "      <td>10.27</td>\n",
              "      <td>2.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>red neuronal adam</td>\n",
              "      <td>10.44</td>\n",
              "      <td>1.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>red neuronal sgd</td>\n",
              "      <td>10.49</td>\n",
              "      <td>1.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>linear regression</td>\n",
              "      <td>10.66</td>\n",
              "      <td>1.67</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               models  test mape  overfitting\n",
              "1  red neuronal lbfgs      10.27         2.35\n",
              "3   red neuronal adam      10.44         1.82\n",
              "2    red neuronal sgd      10.49         1.92\n",
              "0   linear regression      10.66         1.67"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "Qu2UO2fsbOmq",
        "outputId": "50f8ff76-e90c-497b-842f-8b18df3a256a"
      },
      "source": [
        "results.sort_values(by = 'overfitting', ascending=True)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>models</th>\n",
              "      <th>test mape</th>\n",
              "      <th>overfitting</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>linear regression</td>\n",
              "      <td>10.66</td>\n",
              "      <td>1.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>red neuronal adam</td>\n",
              "      <td>10.44</td>\n",
              "      <td>1.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>red neuronal sgd</td>\n",
              "      <td>10.49</td>\n",
              "      <td>1.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>red neuronal lbfgs</td>\n",
              "      <td>10.27</td>\n",
              "      <td>2.35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               models  test mape  overfitting\n",
              "0   linear regression      10.66         1.67\n",
              "3   red neuronal adam      10.44         1.82\n",
              "2    red neuronal sgd      10.49         1.92\n",
              "1  red neuronal lbfgs      10.27         2.35"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmvyloNXbstz"
      },
      "source": [
        "Elijo la Red Neuronal adam dado que muestra el mejor balance entre el test mape y el nivel de overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3Yk6LI4byxz",
        "outputId": "4ae79793-e38a-4dd8-9c7b-a10e61daf77a"
      },
      "source": [
        "pipe = make_pipeline(\r\n",
        "      make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Language(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(BelongsToCollection(), DictVectorizer(sparse=False))        \r\n",
        "    ),\r\n",
        "      StandardScaler(),\r\n",
        "      MLPRegressor(alpha=23, random_state=21, \r\n",
        "                   early_stopping=True, solver = 'adam',\r\n",
        "                   learning_rate_init=0.001)\r\n",
        "    )\r\n",
        "pipe.fit(train_docs, y_train);\r\n",
        "red_neu_adam = test_pipe(pipe)\r\n",
        "print(red_neu_adam)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train_mape': 8.62, 'test_mape': 10.44}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}