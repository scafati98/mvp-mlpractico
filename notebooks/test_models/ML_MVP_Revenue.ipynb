{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML: MVP-Revenue.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBwht1XfyWC"
      },
      "source": [
        "##Modelo de predicción del Revenue de punta a punta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po1WlzbZXQXK"
      },
      "source": [
        "Abrimos el csv e importamos algunas librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nmi9B99j6vL",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "19ae6a0c-8126-4d35-f757-c6ab14fd35ad"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5aa46df5-e1f0-4157-97b9-592944c9dc4b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5aa46df5-e1f0-4157-97b9-592944c9dc4b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving movies_metadata.csv to movies_metadata.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RnsnVP5XDxf"
      },
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np\r\n",
        "import io"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oblb6mvof0Ju",
        "outputId": "87738a80-352b-4927-e55b-6496fe8eb664"
      },
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded['movies_metadata.csv']))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaa2THMrXUAq"
      },
      "source": [
        "###Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLjd4_gFXYAe"
      },
      "source": [
        "####Revenue:\r\n",
        "1. Quitamos valores menores o iguales a 0.\r\n",
        "2. Filtramos el 5% de los valores mas bajos para evitar errores de tipeo.\r\n",
        "3. Normalizamos aplicando el logaritmo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH-Z6aacmc1b"
      },
      "source": [
        "df = df[df.revenue > 0]\r\n",
        "df = df[df.revenue > df.revenue.quantile(.05)]\r\n",
        "\r\n",
        "import math\r\n",
        "def revenue_log(x):\r\n",
        "  return math.log(x)\r\n",
        "\r\n",
        "df['revenue'] = df.revenue.apply(lambda x: revenue_log(x))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oclWQ06BXlhR"
      },
      "source": [
        "####Runtime:\r\n",
        "1. Sacamos valores nulos\r\n",
        "2. Sacamos valores que esten a mas o menos de 2 desviaciones estandar de la media."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVg1KTJpIFM4"
      },
      "source": [
        "df.fillna(0, inplace= True)\r\n",
        "df = df[df.runtime != 0]\r\n",
        "upper_lim = np.mean(df.runtime) + np.std(df.runtime)*2\r\n",
        "lower_lim = np.mean(df.runtime) - np.std(df.runtime)*2\r\n",
        "\r\n",
        "df = df[df.runtime > lower_lim]\r\n",
        "df = df[df.runtime < upper_lim]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd0RmOheXx4-"
      },
      "source": [
        "####Release Date:\r\n",
        "1. Convertimos a tipo de dato datetime.\r\n",
        "2. Nos quedamos solo con el año.\r\n",
        "3. Filtramos todas aquellas peliculas anteriores al 1985"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3ceOdo56c6b"
      },
      "source": [
        "#Convierto la fecha a datetime y me quedo solo con el año\r\n",
        "df['release_date'] = pd.to_datetime(df['release_date'])\r\n",
        "df['year'] = pd.DatetimeIndex(df['release_date']).year\r\n",
        "df = df[df.year > 1985]\r\n",
        "df.drop(columns = ['release_date'], inplace = True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm38Y-g0YBQP"
      },
      "source": [
        "#### Géneros, Países y Colecciones:\r\n",
        "1. Convertimos los diccionarios a listas, quedandonos solo con el valor que nos interesa (name).\r\n",
        "2. En el caso de colecciones dado que hay >700 colecctions con frecuencias bajas la convertimos en un tipo de dato binario. 1 si es parte de una coleccion, 0 caso contrario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GAmPUT0k2Ca"
      },
      "source": [
        "#Desarmo diccionarios y convierto en listas\r\n",
        "\r\n",
        "#Generos\r\n",
        "df['genres'] = df.genres.apply(lambda x: [i['name']  for i in eval(x)])\r\n",
        "\r\n",
        "#Paises\r\n",
        "df['production_countries'] = df.production_countries.apply(lambda x: [i['name']  for i in eval(x)])\r\n",
        "\r\n",
        "#Colecciones\r\n",
        "df['belongs_to_collection'].fillna(0, inplace = True)\r\n",
        "import ast\r\n",
        "def collection_from_dict(x):\r\n",
        "  if x != 0:\r\n",
        "   #convert string to dictionary\r\n",
        "    res = ast.literal_eval(x) \r\n",
        "    #return just the name of the collection\r\n",
        "    return 1\r\n",
        "  return 0\r\n",
        "df['belongs_to_collection'] = df.belongs_to_collection.apply(lambda x: collection_from_dict(x))\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPpFprJNYWTo"
      },
      "source": [
        "###Feature Selection:\r\n",
        "1. Elegimos que variables dropear del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptcykZy_f1rE"
      },
      "source": [
        "df=df.drop(columns = ['adult','budget','homepage','id','original_title',\r\n",
        "                     'overview','popularity','poster_path','production_companies',\r\n",
        "                     'spoken_languages','status', 'tagline', 'title', 'video',\r\n",
        "                     'vote_average','vote_count'], axis=1)\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHtLKpUuYeLZ"
      },
      "source": [
        "###Train and test split:\r\n",
        "1. Cortamos por año (2014) dado que queremos que el modelo aprenda a predecir películas del futuro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTyyzAojhOcH",
        "outputId": "8f0065a8-77d0-426e-9133-b9b7478d9346"
      },
      "source": [
        "#Train and test split\r\n",
        "train_df = df[df.year <= 2014]\r\n",
        "test_df = df[df.year > 2014]\r\n",
        "len(train_df), len(test_df), len(test_df) / len(train_df)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5096, 647, 0.12696232339089483)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gjveGTE62cI"
      },
      "source": [
        "y_train = (train_df.revenue).values\r\n",
        "y_test = (test_df.revenue).values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j557gxzXYorq"
      },
      "source": [
        "###Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4NpY8a6Y0_O"
      },
      "source": [
        "Vamos a usar todo como listas de diccionarios para poder usar el ecosistema de sklearn de forma sencilla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ankmLhaurMWb"
      },
      "source": [
        "train_docs = train_df.to_dict(orient='records')\r\n",
        "test_docs = test_df.to_dict(orient='records')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVY1f6qE2UPa",
        "outputId": "ddd19490-665e-4102-b731-4ee5ccc32292"
      },
      "source": [
        "train_docs[0], test_docs[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'belongs_to_collection': 1,\n",
              "  'genres': ['Animation', 'Comedy', 'Family'],\n",
              "  'imdb_id': 'tt0114709',\n",
              "  'original_language': 'en',\n",
              "  'production_countries': ['United States of America'],\n",
              "  'revenue': 19.7385732187406,\n",
              "  'runtime': 81.0,\n",
              "  'year': 1995},\n",
              " {'belongs_to_collection': 1,\n",
              "  'genres': ['Action', 'Adventure', 'Thriller'],\n",
              "  'imdb_id': 'tt2381249',\n",
              "  'original_language': 'en',\n",
              "  'production_countries': ['China', 'United States of America'],\n",
              "  'revenue': 20.341024173461395,\n",
              "  'runtime': 131.0,\n",
              "  'year': 2015})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol-BesSKZR5e"
      },
      "source": [
        "####Performance metrics:\r\n",
        "1. Medimos el mean absolute percentage error (mape) y el r2 para el train y test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh2iwdwr41gW"
      },
      "source": [
        "from sklearn.metrics import r2_score\r\n",
        "\r\n",
        "def test_pipe(pipe):\r\n",
        "    return {\r\n",
        "        'train_r2': round(r2_score(y_train, pipe.predict(train_docs)),2),\r\n",
        "        'train_mape' : round(np.mean(np.abs(percentage_error(np.asarray(y_train), np.asarray(pipe.predict(train_docs))))) * 100,2),\r\n",
        "        'test_r2': round(r2_score(y_test, pipe.predict(test_docs)),2),\r\n",
        "        'test_mape' : round(np.mean(np.abs(percentage_error(np.asarray(y_test), np.asarray(pipe.predict(test_docs))))) * 100,2)\r\n",
        "    }\r\n",
        "\r\n",
        "def percentage_error(actual, predicted):\r\n",
        "    res = np.empty(actual.shape)\r\n",
        "    for j in range(actual.shape[0]):\r\n",
        "        if actual[j] != 0:\r\n",
        "            res[j] = (actual[j] - predicted[j]) / actual[j]\r\n",
        "        else:\r\n",
        "            res[j] = predicted[j] / np.mean(actual)\r\n",
        "    return res"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFwJCwVrY6BE"
      },
      "source": [
        "####Feature Géneros:\r\n",
        "1. Hacemos variables dummies\r\n",
        "2. La agregamos al pipeline\r\n",
        "3. Fiteamos y medimos el performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmW8VIMbkjbr"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
        "\r\n",
        "class GenreDummies(BaseEstimator, TransformerMixin):\r\n",
        "    def fit(self, X, y): return self\r\n",
        "\r\n",
        "    def transform(self, X):\r\n",
        "        res = []\r\n",
        "        for e in X:\r\n",
        "            res.append({g: 1 for g in e['genres']})\r\n",
        "        return res"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yZZN-lc28B8",
        "outputId": "222ebffb-9803-4739-dde7-509506f0260b"
      },
      "source": [
        "GenreDummies().transform(train_docs[:10])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Animation': 1, 'Comedy': 1, 'Family': 1},\n",
              " {'Adventure': 1, 'Family': 1, 'Fantasy': 1},\n",
              " {'Comedy': 1, 'Drama': 1, 'Romance': 1},\n",
              " {'Comedy': 1},\n",
              " {'Action': 1, 'Adventure': 1, 'Thriller': 1},\n",
              " {'Action': 1, 'Adventure': 1, 'Thriller': 1},\n",
              " {'Comedy': 1, 'Drama': 1, 'Romance': 1},\n",
              " {'Adventure': 1, 'Animation': 1, 'Family': 1},\n",
              " {'Action': 1, 'Adventure': 1},\n",
              " {'Drama': 1, 'Romance': 1}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VLwclqWrfJR"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.feature_extraction import DictVectorizer\r\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXynNZZqZhpe"
      },
      "source": [
        "Armamos el pipeline, lo fiteamos y lo medimos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AaYxGkgrj2T"
      },
      "source": [
        "pipe = make_pipeline(\r\n",
        "    GenreDummies(), DictVectorizer(sparse=False),  \r\n",
        "    LinearRegression()\r\n",
        ")\r\n",
        "\r\n",
        "pipe.fit(train_docs, y_train);"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLMz5CZ8ryWJ",
        "outputId": "ff26c1d8-08a8-448c-c732-12975ee6b51c"
      },
      "source": [
        "pipe.predict(train_docs[:10])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([17.44891585, 18.52694871, 15.96300799, 16.39435353, 17.82423906,\n",
              "       17.82423906, 15.96300799, 18.15229955, 17.56251852, 15.86076097])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR1xaO_i5LLU",
        "outputId": "7ddb3e26-04e8-4224-84ca-4124da418a61"
      },
      "source": [
        "test_pipe(pipe)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_mape': 12.84, 'test_r2': 0.2, 'train_mape': 10.96, 'train_r2': 0.17}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP8x4igG7xh6"
      },
      "source": [
        "####Feature años:\r\n",
        "1. Armamos una variable que indique hace cuantos años se filmo la pelicula.\r\n",
        "2. La agregamos al pipeline, fiteamos y medimos el performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXpwscqE7yXp"
      },
      "source": [
        "from datetime import datetime\r\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
        "\r\n",
        "class YearsAgo(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self):\r\n",
        "        self.now = datetime.now().year\r\n",
        "        \r\n",
        "    def fit(self, X, y): return self\r\n",
        "\r\n",
        "    def transform(self, X):\r\n",
        "        res = []\r\n",
        "        for e in X:\r\n",
        "            res.append({'years_ago': self.now - int(e['year'])})\r\n",
        "        return res"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLSW548Y8KcQ",
        "outputId": "074dcbae-29ee-4a41-9b59-46e75f162171"
      },
      "source": [
        "YearsAgo().transform(train_docs[150:160])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'years_ago': 26},\n",
              " {'years_ago': 27},\n",
              " {'years_ago': 27},\n",
              " {'years_ago': 27},\n",
              " {'years_ago': 27},\n",
              " {'years_ago': 29},\n",
              " {'years_ago': 27},\n",
              " {'years_ago': 27},\n",
              " {'years_ago': 27},\n",
              " {'years_ago': 27}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFlkmecC727f"
      },
      "source": [
        "from sklearn.pipeline import make_union\r\n",
        "\r\n",
        "pipe = make_pipeline(\r\n",
        "    make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False))\r\n",
        "    ),\r\n",
        "    LinearRegression()\r\n",
        ")\r\n",
        "\r\n",
        "pipe.fit(train_docs, y_train);"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1gcRy8y78k4",
        "outputId": "bf0546c0-580a-44af-d774-9f7974d4616d"
      },
      "source": [
        "test_pipe(pipe)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_mape': 12.83, 'test_r2': 0.2, 'train_mape': 10.95, 'train_r2': 0.17}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63VWunkeZ8zJ"
      },
      "source": [
        "####Feature países:\r\n",
        "1. Armamos variables dummies.\r\n",
        "2. La agregamos al pipeline, fiteamos y medimos el performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjS6ncWN94xw"
      },
      "source": [
        "class CountryDummies(BaseEstimator, TransformerMixin):\r\n",
        "    def fit(self, X, y): return self\r\n",
        "\r\n",
        "    def transform(self, X):\r\n",
        "        res = []\r\n",
        "        for e in X:\r\n",
        "            res.append({g: 1 for g in e['production_countries']})\r\n",
        "        return res"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mefFVqC97e4",
        "outputId": "c6bc9fcb-137c-4c73-98d8-c62103ccb268"
      },
      "source": [
        "CountryDummies().transform(train_docs[:10])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'United States of America': 1},\n",
              " {'United States of America': 1},\n",
              " {'United States of America': 1},\n",
              " {'United States of America': 1},\n",
              " {'United States of America': 1},\n",
              " {'United Kingdom': 1, 'United States of America': 1},\n",
              " {'United States of America': 1},\n",
              " {'United States of America': 1},\n",
              " {'France': 1, 'Germany': 1, 'Italy': 1, 'United States of America': 1},\n",
              " {'United Kingdom': 1, 'United States of America': 1}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87ZazfNR-Bn8"
      },
      "source": [
        "from sklearn.pipeline import make_union\r\n",
        "\r\n",
        "pipe = make_pipeline(\r\n",
        "    make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False))\r\n",
        "    ),\r\n",
        "    LinearRegression()\r\n",
        ")\r\n",
        "\r\n",
        "pipe.fit(train_docs, y_train);"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq9x-Tfx-F18",
        "outputId": "1ebcbd82-4920-49d1-832c-eab49898f6ea"
      },
      "source": [
        "test_pipe(pipe)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_mape': 11.87, 'test_r2': 0.29, 'train_mape': 10.15, 'train_r2': 0.26}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdeNA3CZaDW4"
      },
      "source": [
        "####Feature runtime:\r\n",
        "1. Calculamos el runtime máximo.\r\n",
        "2. Normalizamos la variable dividiendola por el runtime máximo.\r\n",
        "3. La añadimos al pipeline, lo fiteamos y medimos el performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2-JZimv_lo0"
      },
      "source": [
        "max_runtime = df.runtime.max()\r\n",
        "\r\n",
        "class Runtime(BaseEstimator, TransformerMixin):\r\n",
        "    def fit(self, X, y): return self\r\n",
        "\r\n",
        "    def transform(self, X):\r\n",
        "        res = []\r\n",
        "        for e in X:\r\n",
        "            res.append({'runtime': e['runtime'] / max_runtime})\r\n",
        "        return res\r\n",
        "\r\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhB5bWiFAUhS",
        "outputId": "c5b0a0f5-e902-458e-d268-6ca187e79c08"
      },
      "source": [
        "Runtime().transform(train_docs[:5])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'runtime': 0.54},\n",
              " {'runtime': 0.6933333333333334},\n",
              " {'runtime': 0.8466666666666667},\n",
              " {'runtime': 0.7066666666666667},\n",
              " {'runtime': 0.7066666666666667}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3mbw70oadtB"
      },
      "source": [
        "#####Regresión Logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC146oKIFCRr"
      },
      "source": [
        "pipe = make_pipeline(\r\n",
        "    make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False))        \r\n",
        "    ),\r\n",
        "    LinearRegression()\r\n",
        ")\r\n",
        "\r\n",
        "pipe.fit(train_docs, y_train);"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpo8hPlUFNZf",
        "outputId": "2179bd5d-6730-4c04-8aea-3c21b307bb03"
      },
      "source": [
        "test_pipe(pipe)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_mape': 11.05, 'test_r2': 0.37, 'train_mape': 9.33, 'train_r2': 0.36}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHI4uZEDaZMU"
      },
      "source": [
        "#####Red Neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFaS9BRdKB8e"
      },
      "source": [
        "from sklearn.neural_network import MLPRegressor\r\n",
        "\r\n",
        "pipe = make_pipeline(\r\n",
        "    make_union(\r\n",
        "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(CountryDummies(), DictVectorizer(sparse=False)),\r\n",
        "        make_pipeline(Runtime(), DictVectorizer(sparse=False))        \r\n",
        "    ),\r\n",
        "    MLPRegressor(random_state=21, max_iter=500)\r\n",
        ")\r\n",
        "\r\n",
        "pipe.fit(train_docs, y_train);"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK91qWnVKLRL",
        "outputId": "c9a03bd9-ab25-4a03-c143-b441c71ee77c"
      },
      "source": [
        "test_pipe(pipe)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_mape': 11.12, 'test_r2': 0.33, 'train_mape': 8.73, 'train_r2': 0.42}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J3rkBOpc_zC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}